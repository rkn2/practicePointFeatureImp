
 

 

 

A drawing of a building

AI-generated content may be incorrect. 

Dr. Rebecca Napolitano 

Heritage 3D Lab: Damage. Data. Design 

ECoRE BuildingN486 | nap@psu.edu 

https://rkn2.github.io/heritage3d-lab/  

The Pennsylvania State University  

College of Engineering 

Department of Architectural Engineering 

https://www.ae.psu.edu/ 

Penn State Architectural Engineering 

 

 

Dear Editors,  

 

Please find attached a revised manuscript of the paper entitled “Dimensionality Reduction for Heritage Preservation: Using Machine Learning to Prioritize Building Preservation Decisions”, submitted for consideration as a Practice Point in the APT Bulletin. We have carefully reviewed and addressed all comments raised by the reviewers. Below, we provide an itemized response to each comment, describing how the manuscript has been revised or clarifying our intent where no textual changes were required. We greatly appreciate the reviewers’ thoughtful feedback, which has helped us clarify the scope, intent, and practical framing of the paper and strengthen its value to preservation practitioners. We thank the editors and reviewers for their time and constructive input, and we appreciate the opportunity to submit this revised manuscript for consideration. Please do not hesitate to contact us should any additional information be required. 

 

 

 

Dr. Rebecca Napolitano (nap@psu.edu)  |  Assistant Professor | Director of the Heritage 3D lab 

Department of Architectural Engineering | The Pennsylvania State University 

 

 

 

 

Authors Response to Reviewer Comments 

 

Reviewer 1 

1. The article marries the analysis processes of the data collected and reviews for factor analysis and feature importance.  I would like to see a case study of an application of the process on a specific structure. 

 

2. It would seem to me that the variables of the construction types, location, size, and age need to be discussed and be part of the initial data analysis. 

 

3. This is the Black and White of Preservation and conservation but I think the point needs to be made that solutions often don’t just lie at the feet of the preservation architect but is a collaboration of structural, MEP, and building envelope experts. 

 

4. The second to last paragraph in this section is clunky and could use 2 subservient or directly state that it will be addressed in another section.  

paragraphs to lay out a direct example of both the two complementary techniques.  

 

5. In the last paragraph it would be helpful to know who it is that models the conservation plans deployed by the interactive notebook? Where does this come from? NPS Case studies? A book? Who/What is training these models? 

 

Project Planning: Scoping Your Data-Driven Project 

Forming questions you want answers to before breaking into all the details of the data is a great approach in any research, not just in framing questions for an AI model.  

 

Defining Your Questions 

Do we regularly run into projects where there is true uncertainty about which parameters matter the most? Typically, we triage these quickly and correctly.  

A lot of input from observations are required to get anything of merit or leverage from the model.  

Data quality. Good in = good out.  

Bad data can lead to false correlations 

 

Exploratory Data Visualization 

The example is a bit convoluted. The graph has too many unrelated instances and would not be helpful in determining data or outcomes. Realistically, Figure 2 seems to provide an example of how AI could become confused on what connections to draw within a set of data, an example of bad in = bad out.  

 

Factor Analysis 

What It Does 

Shouldn’t the architect already know about these correlations? I realize this is an example, but is there another example of what the AI could bring forward to the conservationist’s attention that would be beneficial?  

So the idea is that it can flatten some data sets in order to reduce dimensionality or complexity.  

 

The Process  

Naming and organizing the factors is a great method in building your analysis.  

 

Feature Importance 

What It Does 

“Feature importance analysis ranks individual variables by their predictive power for specific outcomes.” Sounds stronger than the first tool. (Factor analysis)  

Could be used if you need to narrow down which building is the best candidate for intervention and have a larger inventory of buildings in need.  

 

Decision Framework: Reconciling Models with Field Observations 

A process of troubleshooting is described when the results conflict with reality.  

How often does this happen in practice?  

 

My final thoughts 

I am not convinced that the output of the models will be remarkably rewarding enough for the effort that goes into structuring and feeding the model. As of yet, the best reward listed here in the results is that it gives you additional confidence or backs up what you already know. This is far from insightful. It could even run into bias confirmation.  

 

>> Addressing Comment: * The article marries the analysis processes of the data collected and reviews for factor analysis and feature importance.  I would like to see a case study of an application of the process on a specific structure. 

 

We thank the reviewer for this helpful suggestion. In response, we have added a new subsection, “Demonstrated Applications in Post-Disaster Heritage Contexts” (Section 3.2.7), which situates the proposed workflow within real-world heritage applications previously undertaken by the authors. Rather than introducing a new, fully detailed case study, which would extend beyond the scope of a Practice Point, we summarize how the same analytical logic (combining dimensionality reduction and feature importance) has been applied in post-disaster assessments following the 2020 Beirut port explosion and the 2023 Kakhovka Dam breach in Ukraine. This addition demonstrates how the workflow performs on actual heritage datasets, highlights the types of insights it reveals at the level of individual buildings and building attributes, and clarifies how results informed prioritization and interpretation in practice. We believe this approach strengthens the paper by grounding the methods in applied experience while maintaining its instructional focus. 

 

 

 

 

>> Addressing Comment: * It would seem to me that the variables of the construction types, location, size, and age need to be discussed and be part of the initial data analysis. 

 

We thank the reviewer for this comment. As this article is intended as a Practice Point rather than an analysis of a fixed dataset, the workflow is designed to be adaptable to a wide range of attribute types rather than to emphasize specific variables. That said, we agree that fundamental building descriptors such as construction type, age, size, and location are commonly included among the attributes available to practitioners and should be acknowledged within the analytical framework. To address this point more explicitly, we have revised the Introduction to note that historic cores typically comprise buildings of varied construction types, sizes, and construction periods, clarifying that such descriptors commonly form part of the attribute sets to which the proposed workflow may be applied. This clarification makes the scope of applicable attributes more explicit without prescribing a required dataset. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

>> Addressing Comment: * This is the Black and White of Preservation and conservation but I think the point needs to be made that solutions often don’t just lie at the feet of the preservation architect but is a collaboration of structural, MEP, and building envelope experts. 

 

Thank you for this comment. We agree that preservation and conservation decisions are inherently collaborative and typically involve structural, MEP, and building envelope expertise in addition to preservation professionals. To make this more explicit, we have revised the manuscript to clarify that the analytical outputs discussed in this practice point are intended to support interdisciplinary decision-making rather than to assign responsibility to a single discipline. This addition emphasizes that data-driven insights are most effective when integrated into collaborative workflows that combine architectural, structural, and building systems expertise. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

>> Addressing Comment: * The second to last paragraph in this section is clunky and could use 2 subservient or directly state that it will be addressed in another section.  

paragraphs to lay out a direct example of both the two complementary techniques. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

>> Addressing Comment: * In the last paragraph it would be helpful to know who it is that models the conservation plans deployed by the interactive notebook? Where does this come from? NPS Case studies? A book? Who/What is training these models? 

 

We thank the reviewer for this important clarification. The interactive notebooks described in the paper do not generate or model conservation plans, nor are they trained on predefined intervention strategies. Rather, the models operate on user-provided project data to identify patterns and influential variables, while interpretation and selection of conservation actions remain the responsibility of the practitioner, informed by existing guidance, standards, and professional expertise. We have revised the manuscript to make this distinction explicit in the relevant paragraph. 

 

 

>> Addressing Comment: * Exploratory Data Visualization 

The example is a bit convoluted. The graph has too many unrelated instances and would not be helpful in determining data or outcomes. Realistically, Figure 2 seems to provide an example of how AI could become confused on what connections to draw within a set of data, an example of bad in = bad out.  

 

We thank the reviewer for this observation. The exploratory data visualization example is naturally complex, as it reflects the heterogeneous and weakly correlated nature of many real-world heritage datasets. The purpose of this figure is not to suggest a finalized analytical outcome or model confusion, but rather to illustrate how exploratory visualization is used diagnostically to identify noise, redundancy, and non-obvious relationships prior to applying dimensionality reduction or feature importance methods. As such, the example is meant to demonstrate the importance of early-stage data inspection rather than to imply “bad input” or misleading results. 

 

>> Addressing Comment: * Factor Analysis / What It Does 

Shouldn’t the architect already know about these correlations? I realize this is an example, but is there another example of what the AI could bring forward to the conservationist’s attention that would be beneficial?  

So the idea is that it can flatten some data sets in order to reduce dimensionality or complexity.  

 

We appreciate the reviewer’s thoughtful question. While experienced practitioners may already have qualitative expectations about certain relationships between variables, not all relationships within complex, multivariate datasets are obvious or intuitive. Some interactions are subtle, indirect, or only emerge when multiple variables are considered simultaneously across many buildings or over time. Factor analysis contributes value by systematically uncovering these hidden or complex patterns, quantifying the strength of relationships, and organizing large numbers of variables into interpretable structures. The intent is therefore not to replace professional knowledge, but to support it by revealing dominant patterns and non-obvious associations that merit closer expert interpretation, particularly when dataset size and complexity exceed what can be reliably assessed through intuition alone. 

 

>> Addressing Comment: * Feature Importance / What It Does 

“Feature importance analysis ranks individual variables by their predictive power for specific outcomes.” Sounds stronger than the first tool. (Factor analysis)  

Could be used if you need to narrow down which building is the best candidate for intervention and have a larger inventory of buildings in need.  

 

We thank the reviewer for this observation. Feature importance analysis is indeed more outcome-oriented, as it explicitly ranks variables based on their predictive relationship to a defined target, making it particularly useful for prioritization tasks such as identifying candidate buildings for intervention within large inventories. Factor analysis, by contrast, serves a different but complementary role by exploring underlying structure and relationships within the data without reference to a specific outcome. The tools are therefore not intended to be hierarchical in strength, but complementary in purpose: factor analysis supports understanding and dimensionality reduction, while feature importance supports prioritization and decision-making once an outcome of interest is defined. 

 

>> Addressing Comment: * Decision Framework: Reconciling Models with Field Observations 

A process of troubleshooting is described when the results conflict with reality.  

How often does this happen in practice?  

 

We thank the reviewer for this question. In practice, discrepancies between model outputs and field observations are not uncommon, particularly in heritage contexts where data are heterogeneous, incomplete, or temporally misaligned. Such conflicts typically arise during early or exploratory applications of data-driven methods, when data quality, variable selection, or recent site changes have not yet been fully accounted for. The troubleshooting process described is therefore intended as a practical safeguard rather than an exceptional scenario, reflecting normal iterative use of analytical tools alongside professional judgment. As models are refined and datasets improve, the frequency and magnitude of such conflicts generally decrease. 

 

>> Addressing Comment: * My final thoughts 

I am not convinced that the output of the models will be remarkably rewarding enough for the effort that goes into structuring and feeding the model. As of yet, the best reward listed here in the results is that it gives you additional confidence or backs up what you already know. This is far from insightful. It could even run into bias confirmation.  

 

We appreciate the reviewer’s candid assessment and agree that the value of any analytical framework must justify the effort required to implement it. The intent of the proposed workflow is not to produce novel insights for novelty’s sake, nor to replace professional judgment, but to address specific limitations that arise in contemporary preservation practice when decision-making must occur across large, heterogeneous building datasets. 

 

In such contexts, the primary benefit is not simply “additional confidence,” but the ability to systematically prioritize, quantify trade-offs, and make decision logic explicit where intuition alone becomes inconsistent or difficult to defend. These methods allow practitioners to move beyond general knowledge (like for example “moisture matters” or “older buildings are vulnerable”) and instead determine which factors matter most in a given dataset, to what relative degree, and for which subsets of buildings. This distinction is particularly important when resources are limited and interventions must be ranked rather than simply justified individually. 

 

With respect to confirmation bias, the framework is explicitly designed to reduce it rather than reinforce it. By testing assumptions against the full dataset, the methods can expose cases where expected relationships are weak, absent, or context-dependent, and where different variables emerge as dominant drivers than initially anticipated. In practice, this often leads not only to confirmation of known mechanisms, but to their re-weighting, re-contextualization, or selective dismissal; outcomes that are difficult to achieve through qualitative reasoning alone. 

 

Ultimately, the reward of the workflow lies in enabling transparent, repeatable, and defensible prioritization decisions at scale, particularly when communicating with stakeholders, funding agencies, or review bodies. In preservation practice, where accountability and consistency are as critical as technical insight, these outcomes represent a meaningful and practical contribution rather than a redundant one. 

 

 

 

 

 

Reviewer 2 

 

The practice point is highly innovative and shows strong potential for wide application in the heritage field. To further enhance its clarity, accessibility, and usefulness for practitioners, the following suggestions are offered: 

 

• It would be helpful to include a table summarising what a heritage practitioner should be able to provide or understand in order to apply the proposed machine-learning approaches effectively and obtain robust results. 

• A short bullet-point list outlining the skills required of the heritage practitioner would add clarity, including whether the intended users are planners, structural engineers, architects, conservators, or other professionals, and highlighting the interdisciplinary knowledge involved. 

• A simple flowchart illustrating the overall process—from data acquisition and preparation to analysis, interpretation, and decision-making—would make the methodology easier to follow. 

• Including a small number of illustrative examples demonstrating good results, poor results, and cases with higher uncertainty would help readers better appreciate both the potential and the limitations of the approach. 

 

Finally, the practice point could benefit from a more graphical presentation overall. While charts are effective, complementing them with additional visual elements tailored to heritage and planning audiences may improve accessibility and broaden its appeal. 

 

>> Addressing Comment: * It would be helpful to include a table summarising what a heritage practitioner should be able to provide or understand in order to apply the proposed machine-learning approaches effectively and obtain robust results. 

 

We thank the reviewer for this excellent suggestion. To clarify the requirements for potential users, we have added Table 1 in Section 2 ("Project Planning"). This table explicitly summarizes the data artifacts a practitioner must provide (e.g., structured datasets, consistent units) and the domain skills they must possess (e.g., interpretation of pathology) to use the tools effectively. We also clarified that while domain expertise is critical, programming skill is not required. 

 

 

 

>> Addressing Comment: * A short bullet-point list outlining the skills required of the heritage practitioner would add clarity, including whether the intended users are planners, structural engineers, architects, conservators, or other professionals, and highlighting the interdisciplinary knowledge involved. 

 

We have added a paragraph in Section 2 (Project Planning) to clarify the intended audience and required interdisciplinary skills. This text complements Table 1 by explicitly identifying how different professionals (Preservation Planners, Structural Engineers & Architects, and Conservators) can leverage these methods. We emphasize that impactful preservation outcomes require collaborative interpretation, combining the statistical outputs of these models with domain-specific knowledge of material decay and structural behavior. 

 

>> Addressing Comment: * A simple flowchart illustrating the overall process—from data acquisition and preparation to analysis, interpretation, and decision-making—would make the methodology easier to follow. 

 

 

We thank the reviewer for this suggestion. We agree that a visual roadmap is necessary for making the methodology accessible to a broad audience. We have added Figure xxx (Methodological Flowchart) to Section 3 of the revised manuscript. This diagram visually delineates the stages of the workflow: beginning with Data Acquisition & Preparation, branching into the parallel tracks of exploratory Factor Analysis and predictive Feature Importance, and converging on Interpretation and Decision Making. Additionally, the flowchart includes an iterative feedback loop, illustrating how discrepancies between model outputs and field observations should prompt data refinement, as discussed in our response to Reviewer 1. 

 

 

>> Addressing Comment: * Including a small number of illustrative examples demonstrating good results, poor results, and cases with higher uncertainty would help readers better appreciate both the potential and the limitations of the approach. 

 

 

We appreciate this suggestion. Rather than adding text to the manuscript itself (which is limited in space), we have enhanced the companion notebook ( 

03_feature_importance.ipynb) to include a dedicated "Interpretation Guide: Illustrative Scenarios". 

This new section explicitly walks users through three concrete outcomes: 

The "Good Result" (Convergent Evidence): Where high importance scores align with field observations, validating intervention priorities. 

The "Poor Result" (Model Failure): Where predictions conflict with reality (often due to unmeasured stochastic events), signaling the need for data enrichment rather than model trust. 

The "Uncertain Result" (Ambiguity): Where intermediate scores and high variance signal the need for targeted sensor deployment rather than immediate action. 

We have added a reference to this guide in Section 4 (Implementation) of the manuscript to direct readers to these practical examples: "For illustrative scenarios demonstrating convergent evidence, model failure, and high uncertainty, refer to the 'Interpretation Guide' within the feature importance notebook." 

>> Addressing Comment: * Finally, the practice point could benefit from a more graphical presentation overall. While charts are effective, complementing them with additional visual elements tailored to heritage and planning audiences may improve accessibility and broaden its appeal. 

 

 

We agree that visual accessibility is critical for this interdisciplinary audience. In response, we have ensured the manuscript includes: 1) A high-level visual roadmap connecting the data inputs (heritage datasets) to the analytical outputs (prioritization decisions), designed specifically for non-technical readers. 2) we have prioritized figures that map statistical results directly to physical building contexts (e.g., Figure xxx showing risk clusters) rather than relying solely on abstract plots. 

 

 